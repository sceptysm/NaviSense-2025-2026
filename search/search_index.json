{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Project Documentation \u00b6 Welcome to the NaviSense project docs! Here you'll find key artifacts and design information. For guidance on how to manage the Documentation click here . Description \u00b6 Start here with the overall aim, scope, and other information about the project. Project Description Product Requirements 2025/2026 \u00b6 This document outlines the features that the dev product must be capable of by the end of the 2025/2026 TU/e Honors year. Product Requirements 2025/2026 Decisions \u00b6 The following document describes major design decisions along with their drivers. This includes the information like dependencies and technology chosen for the product on the basis of aspects like information about the end-user and cost of development. Design Decisions","title":"Home"},{"location":"#project-documentation","text":"Welcome to the NaviSense project docs! Here you'll find key artifacts and design information. For guidance on how to manage the Documentation click here .","title":"Project Documentation"},{"location":"#description","text":"Start here with the overall aim, scope, and other information about the project. Project Description","title":"Description"},{"location":"#product-requirements-20252026","text":"This document outlines the features that the dev product must be capable of by the end of the 2025/2026 TU/e Honors year. Product Requirements 2025/2026","title":"Product Requirements 2025/2026"},{"location":"#decisions","text":"The following document describes major design decisions along with their drivers. This includes the information like dependencies and technology chosen for the product on the basis of aspects like information about the end-user and cost of development. Design Decisions","title":"Decisions"},{"location":"how-to-use/","text":"How To Use \u00b6 Using the NaviSense DocTree is simple. You are already on the home page of the documentation, and accessing any document related to the project and its codebase can be done here. Each main document can be found on this home page and is given their own section along with a short description. All the subsections of the DocTree can also be accessed through the Section List by the left side of this page (as you can no doubt verify). On Adjusting the Documentation \u00b6 The documentation is deployed through Mkdocs. This means that each page, or document for that matter, found in this documentation, other than links to PDFs, is generated from markdown files. The structure of this DocTree is defined in mkdocs.yml which can be found in the root folder of the codebase . The Sections can be found within the codebase under root/docs/ and it is here where any changes to the Documentation can be made. Adding new Sections requires only the creation of a new markdown file and for that file to also be added to the mkdocs.yml.","title":"Documentation Guide"},{"location":"how-to-use/#how-to-use","text":"Using the NaviSense DocTree is simple. You are already on the home page of the documentation, and accessing any document related to the project and its codebase can be done here. Each main document can be found on this home page and is given their own section along with a short description. All the subsections of the DocTree can also be accessed through the Section List by the left side of this page (as you can no doubt verify).","title":"How To Use"},{"location":"how-to-use/#on-adjusting-the-documentation","text":"The documentation is deployed through Mkdocs. This means that each page, or document for that matter, found in this documentation, other than links to PDFs, is generated from markdown files. The structure of this DocTree is defined in mkdocs.yml which can be found in the root folder of the codebase . The Sections can be found within the codebase under root/docs/ and it is here where any changes to the Documentation can be made. Adding new Sections requires only the creation of a new markdown file and for that file to also be added to the mkdocs.yml.","title":"On Adjusting the Documentation"},{"location":"way-of-working/","text":"Way of Working \u00b6 A Guide to Our Collaborative Process \u00b6 This document outlines the development methodology, communication channels, and collaborative practices for our project. The aim is to agree on shared methods of working to improve collaboration efficiency. The key topics covered are: - Two-Week Sprint Cycle - Communication Channels - Knowledge Management Two-Week Sprint Cycle \u00b6 The project follows an agile development framework centered around two-week sprints . The team works backwards from high-level objectives, breaking them into manageable tasks while allowing flexibility to adapt to issues as they arise. Sprint Phases \u00b6 1. Sprint Planning \u00b6 At the beginning (or end) of each two-week cycle, the team reviews the project backlog and selects tasks for the upcoming sprint. The goal is to ensure: - A realistic workload - Clear and well-defined objectives 2. Development \u00b6 During the sprint, development proceeds according to the communication and coding guidelines defined in later sections. 3. Sprint Review \u00b6 At the end of each sprint, the team conducts the following activities: a. Review Each developer presents a brief demo of their work and records any feedback from the client or team members. b. Retrospective The team reflects on: - What worked well - What could be improved - Any obstacles encountered c. Backlog Update Completed items are signed off, and new tasks are added based on sprint outcomes. Project Backlog \u00b6 The sprint process relies on a Project Backlog , currently maintained on the Clickup platform. Each backlog item should include: - A brief description - Priority level (High / Medium / Low) - Estimated effort Each backlog item must, most critically, be written in a testable manner - i.e. it should be easily understandable whether a task is complete OR not. Simple binary If a backlog item contains within it too many aspects to keep it reasonably simple, create additional subtask that decouple the responsibilities. The benefit of the subtasks is exactly that they become more easily testable, and division of tasks more paletable. Communication Channels \u00b6 The team uses multiple communication channels to keep discussions organized and easy to reference. Discord: Development Hub \u00b6 Discord serves as the primary development communication platform. 1. Formal Discussions Log \u00b6 All technical and design discussions should be logged in a dedicated Discussions channel to create a searchable decision history. This also applies to development issues where feedback from the team is needed. Each discussion should follow this structure: Discussion Topic Brief description of the topic Example: Issue A \u2013 User Authentication Problem Topic Description Clear scope of the issue Example: As part of feature X, we must implement user authentication. I am encountering problem Y. Discussion Messages Messages exchanged between team members Decision Summary A final post summarizing the agreed outcome of the discussion 2. Information Hub \u00b6 The main Discord channel contains links to essential project resources, including: - GitHub repository - OneDrive - Other relevant tools WhatsApp: Social and Personal Coordination \u00b6 WhatsApp is reserved for informal and logistical communication, including: - Checking in on team well-being - Coordinating meetings - Non-technical discussions Communication with the Client \u00b6 Client communication occurs at the start of each sprint cycle During the first sprint , objectives are communicated via email to: j.pintado@student.tue.nl For subsequent sprints, emails should include: Progress update from the previous sprint Objectives for the upcoming sprint Email subject format: Sprint Cycle # Update (where # is the sprint number) Monthly Updates \u00b6 Updates on other events (e.g., TU/e contest) are sent on the first day of each month Updates should include current progress and reflections Meetings \u00b6 Full-team meetings occur: - At the beginning of the year - Before the Midterm Presentation - Before Demo Day Additional questions or requests where the client can help may be handled via WhatsApp. Knowledge Management \u00b6 This section describes how the team captures and maintains knowledge throughout the project. 1. DocTree \u00b6 The DocTree is the definitive version of all the documentation kept for this project. Guides, decisions, design, project descriptions - these types of documents can all be found inside the DocTree. _TODO: Guide to adding new documents, guide on writing docs. 2. Cloud OneDrive \u00b6 The shared OneDrive stores all non-code project assets . Contents include: - Project Foundations \u2013 project descriptions, user personas, and long-term vision documents - Past Context \u2013 reports and materials from previous years - Research and Research Briefs \u2013 sources and research materials - Design and Architecture \u2013 detailed architecture and design documents - Organizational Documents \u2013 project backlog and sprint planning files 3. GitHub Repository \u00b6 All code is managed through a shared GitHub repository using a structured workflow. a. Feature Branch Workflow \u00b6 New features must be developed on a branch created from the main development branch Branches should follow the naming convention: feature-x-branch Example: user-login-branch b. Merge Requests \u00b6 Once a feature is complete and tested locally, a merge request is opened. Each merge request must include: - A clear description of the changes - Relevant context for reviewers c. Meaningful Commit Messages \u00b6 Clear and descriptive commit messages are mandatory. For significant feature work, commit messages should follow this structure: [Task or Feature Name] Feature Description: I implemented the user registration endpoint by creating a new service and repository in the auth module. Next Steps: To complete the user login feature, I still need to implement token generation. d. Archive Old Branch \u00b6 Once a merge request with a feature is passed, archive the old branch to keep the repository clean.","title":"Way of Working"},{"location":"way-of-working/#way-of-working","text":"","title":"Way of Working"},{"location":"way-of-working/#a-guide-to-our-collaborative-process","text":"This document outlines the development methodology, communication channels, and collaborative practices for our project. The aim is to agree on shared methods of working to improve collaboration efficiency. The key topics covered are: - Two-Week Sprint Cycle - Communication Channels - Knowledge Management","title":"A Guide to Our Collaborative Process"},{"location":"way-of-working/#two-week-sprint-cycle","text":"The project follows an agile development framework centered around two-week sprints . The team works backwards from high-level objectives, breaking them into manageable tasks while allowing flexibility to adapt to issues as they arise.","title":"Two-Week Sprint Cycle"},{"location":"way-of-working/#sprint-phases","text":"","title":"Sprint Phases"},{"location":"way-of-working/#1-sprint-planning","text":"At the beginning (or end) of each two-week cycle, the team reviews the project backlog and selects tasks for the upcoming sprint. The goal is to ensure: - A realistic workload - Clear and well-defined objectives","title":"1. Sprint Planning"},{"location":"way-of-working/#2-development","text":"During the sprint, development proceeds according to the communication and coding guidelines defined in later sections.","title":"2. Development"},{"location":"way-of-working/#3-sprint-review","text":"At the end of each sprint, the team conducts the following activities: a. Review Each developer presents a brief demo of their work and records any feedback from the client or team members. b. Retrospective The team reflects on: - What worked well - What could be improved - Any obstacles encountered c. Backlog Update Completed items are signed off, and new tasks are added based on sprint outcomes.","title":"3. Sprint Review"},{"location":"way-of-working/#project-backlog","text":"The sprint process relies on a Project Backlog , currently maintained on the Clickup platform. Each backlog item should include: - A brief description - Priority level (High / Medium / Low) - Estimated effort Each backlog item must, most critically, be written in a testable manner - i.e. it should be easily understandable whether a task is complete OR not. Simple binary If a backlog item contains within it too many aspects to keep it reasonably simple, create additional subtask that decouple the responsibilities. The benefit of the subtasks is exactly that they become more easily testable, and division of tasks more paletable.","title":"Project Backlog"},{"location":"way-of-working/#communication-channels","text":"The team uses multiple communication channels to keep discussions organized and easy to reference.","title":"Communication Channels"},{"location":"way-of-working/#discord-development-hub","text":"Discord serves as the primary development communication platform.","title":"Discord: Development Hub"},{"location":"way-of-working/#1-formal-discussions-log","text":"All technical and design discussions should be logged in a dedicated Discussions channel to create a searchable decision history. This also applies to development issues where feedback from the team is needed. Each discussion should follow this structure: Discussion Topic Brief description of the topic Example: Issue A \u2013 User Authentication Problem Topic Description Clear scope of the issue Example: As part of feature X, we must implement user authentication. I am encountering problem Y. Discussion Messages Messages exchanged between team members Decision Summary A final post summarizing the agreed outcome of the discussion","title":"1. Formal Discussions Log"},{"location":"way-of-working/#2-information-hub","text":"The main Discord channel contains links to essential project resources, including: - GitHub repository - OneDrive - Other relevant tools","title":"2. Information Hub"},{"location":"way-of-working/#whatsapp-social-and-personal-coordination","text":"WhatsApp is reserved for informal and logistical communication, including: - Checking in on team well-being - Coordinating meetings - Non-technical discussions","title":"WhatsApp: Social and Personal Coordination"},{"location":"way-of-working/#communication-with-the-client","text":"Client communication occurs at the start of each sprint cycle During the first sprint , objectives are communicated via email to: j.pintado@student.tue.nl For subsequent sprints, emails should include: Progress update from the previous sprint Objectives for the upcoming sprint Email subject format: Sprint Cycle # Update (where # is the sprint number)","title":"Communication with the Client"},{"location":"way-of-working/#monthly-updates","text":"Updates on other events (e.g., TU/e contest) are sent on the first day of each month Updates should include current progress and reflections","title":"Monthly Updates"},{"location":"way-of-working/#meetings","text":"Full-team meetings occur: - At the beginning of the year - Before the Midterm Presentation - Before Demo Day Additional questions or requests where the client can help may be handled via WhatsApp.","title":"Meetings"},{"location":"way-of-working/#knowledge-management","text":"This section describes how the team captures and maintains knowledge throughout the project.","title":"Knowledge Management"},{"location":"way-of-working/#1-doctree","text":"The DocTree is the definitive version of all the documentation kept for this project. Guides, decisions, design, project descriptions - these types of documents can all be found inside the DocTree. _TODO: Guide to adding new documents, guide on writing docs.","title":"1. DocTree"},{"location":"way-of-working/#2-cloud-onedrive","text":"The shared OneDrive stores all non-code project assets . Contents include: - Project Foundations \u2013 project descriptions, user personas, and long-term vision documents - Past Context \u2013 reports and materials from previous years - Research and Research Briefs \u2013 sources and research materials - Design and Architecture \u2013 detailed architecture and design documents - Organizational Documents \u2013 project backlog and sprint planning files","title":"2. Cloud OneDrive"},{"location":"way-of-working/#3-github-repository","text":"All code is managed through a shared GitHub repository using a structured workflow.","title":"3. GitHub Repository"},{"location":"way-of-working/#a-feature-branch-workflow","text":"New features must be developed on a branch created from the main development branch Branches should follow the naming convention: feature-x-branch Example: user-login-branch","title":"a. Feature Branch Workflow"},{"location":"way-of-working/#b-merge-requests","text":"Once a feature is complete and tested locally, a merge request is opened. Each merge request must include: - A clear description of the changes - Relevant context for reviewers","title":"b. Merge Requests"},{"location":"way-of-working/#c-meaningful-commit-messages","text":"Clear and descriptive commit messages are mandatory. For significant feature work, commit messages should follow this structure: [Task or Feature Name] Feature Description: I implemented the user registration endpoint by creating a new service and repository in the auth module. Next Steps: To complete the user login feature, I still need to implement token generation.","title":"c. Meaningful Commit Messages"},{"location":"way-of-working/#d-archive-old-branch","text":"Once a merge request with a feature is passed, archive the old branch to keep the repository clean.","title":"d. Archive Old Branch"},{"location":"architecture/design-decisions/","text":"Design Decisions \u00b6 As with all projects, NaviSense (especially NaviSense) has encountered many design decisions that forced it to change technologies and approaches to our given problem . In this document, we list Design choices we made and Technologies we picked to develop our solution while describing the design drivers, i.e. why a decision was made, and some alternatives considered. Computer Vision \u00b6 Computer Vision is an approach to spatial analysis that uses machines to infer meaningful data from images and videos taken by a camera. With an input dataset of imagery, Computer Vision techniques can allow us to retrieve an accurate \"scan\", aka point cloud , through photogrammetry and the like, that can represent a given room and act the basis of location mapping. As of 2025/2026, we found that developing a Computer Vision App can work well to solve the problem of navigating visually impaired people indoors. One of the reasons why we have determined that we should use Computer Vision is the ease with which we can develop solutions with it. Currently, there are many open-source libraries that have already implemented machine learning and photogrammetry techniques. This means that we do not have to code the techniques from scratch while still maintaining access to well-performing libraries in this area. Additionally, our interviews with the end-users indicated that most of them need their hands free, as they like to have a walking stick in on hand and their phone in the other. This insight, taken as an assumption on the preferences of the end-user, means that any solution that the user would need to hold would not be very popular with the user. Unless, we are able to utilize the phone that is. Every single phone nowadays has access to a good camera as well as considerably powerful processing units, which allows us to develop the app without the need to plan out the hardware of the solution or pay for any components for that matter. Another reason to consider is that future phones are likely to work even better with Computer Vision. As time progresses, every single computing device improves with both power, and the quality of its components. The obvious increase in quality can happen to the Camera, which should make real time room scans better. However, there is in fact a more interesting future benefit of using a phone app as the solution to our problem - currently, the only major problem seems to be that white, near identical, spaces are hard to distinguish unless one is utilizing a memory mechanism, i.e. by recording the space traversed by the user, to localize the user. A very common solution to this problem is to use LiDAR to accompany the visual footage with depth analysis of the point cloud, as well as real-time localisation. At this time, the use of LiDAR is both very expensive, and would require the creation of an additional device for the user to wear. However, some of the newest phones are already equipped with a LiDAR themselves! or also support other means of depth analysis! As time progresses, this technology is bound to be a more prevalent feature of the common phone, and as such, will support the Computer Vision Phone App solution even better. It is important to note some of the alternatives we considered; we list them and their issues briefly. These include Ultra-Widebands, LiDAR, and Wi-Fi and Bluetooth Triangulation. The problem with Ultra-Widebands is two-fold: two expensive, and difficult to set up. As Ultra-Widebands are a beacon-based technology, meaning they require a crew to setup actual beacons/devices around a complex to map it out, it would be both expensive to have a crew for setting it up, as well as inconvenient when it comes to figuring out the legalistic side of things behind implementing this in public spaces. In particular, we have been tipped of that beacon-based technologies are especially unpopular with the 'hosting' client. These also include Wi-Fi and Bluetooth Triangulation as these also work on a set up network of beacons that triangulate the directions of incoming signals to infer the end-user's position. Moreover, Wi-Fi and Bluetooth have been found to be quite inaccurate when it comes to indoor localisation, which is crucial for a visually impaired user that is really relying on accurate information to be provided to him about the space they are in at all times. Lastly, we have found LiDAR on its own to be ridiculously expensive to get when it is a reliable, fast one, or completely inadequate for personal use when the LiDAR is cheap. You can find further information on these findings here .","title":"Decisions"},{"location":"architecture/design-decisions/#design-decisions","text":"As with all projects, NaviSense (especially NaviSense) has encountered many design decisions that forced it to change technologies and approaches to our given problem . In this document, we list Design choices we made and Technologies we picked to develop our solution while describing the design drivers, i.e. why a decision was made, and some alternatives considered.","title":"Design Decisions"},{"location":"architecture/design-decisions/#computer-vision","text":"Computer Vision is an approach to spatial analysis that uses machines to infer meaningful data from images and videos taken by a camera. With an input dataset of imagery, Computer Vision techniques can allow us to retrieve an accurate \"scan\", aka point cloud , through photogrammetry and the like, that can represent a given room and act the basis of location mapping. As of 2025/2026, we found that developing a Computer Vision App can work well to solve the problem of navigating visually impaired people indoors. One of the reasons why we have determined that we should use Computer Vision is the ease with which we can develop solutions with it. Currently, there are many open-source libraries that have already implemented machine learning and photogrammetry techniques. This means that we do not have to code the techniques from scratch while still maintaining access to well-performing libraries in this area. Additionally, our interviews with the end-users indicated that most of them need their hands free, as they like to have a walking stick in on hand and their phone in the other. This insight, taken as an assumption on the preferences of the end-user, means that any solution that the user would need to hold would not be very popular with the user. Unless, we are able to utilize the phone that is. Every single phone nowadays has access to a good camera as well as considerably powerful processing units, which allows us to develop the app without the need to plan out the hardware of the solution or pay for any components for that matter. Another reason to consider is that future phones are likely to work even better with Computer Vision. As time progresses, every single computing device improves with both power, and the quality of its components. The obvious increase in quality can happen to the Camera, which should make real time room scans better. However, there is in fact a more interesting future benefit of using a phone app as the solution to our problem - currently, the only major problem seems to be that white, near identical, spaces are hard to distinguish unless one is utilizing a memory mechanism, i.e. by recording the space traversed by the user, to localize the user. A very common solution to this problem is to use LiDAR to accompany the visual footage with depth analysis of the point cloud, as well as real-time localisation. At this time, the use of LiDAR is both very expensive, and would require the creation of an additional device for the user to wear. However, some of the newest phones are already equipped with a LiDAR themselves! or also support other means of depth analysis! As time progresses, this technology is bound to be a more prevalent feature of the common phone, and as such, will support the Computer Vision Phone App solution even better. It is important to note some of the alternatives we considered; we list them and their issues briefly. These include Ultra-Widebands, LiDAR, and Wi-Fi and Bluetooth Triangulation. The problem with Ultra-Widebands is two-fold: two expensive, and difficult to set up. As Ultra-Widebands are a beacon-based technology, meaning they require a crew to setup actual beacons/devices around a complex to map it out, it would be both expensive to have a crew for setting it up, as well as inconvenient when it comes to figuring out the legalistic side of things behind implementing this in public spaces. In particular, we have been tipped of that beacon-based technologies are especially unpopular with the 'hosting' client. These also include Wi-Fi and Bluetooth Triangulation as these also work on a set up network of beacons that triangulate the directions of incoming signals to infer the end-user's position. Moreover, Wi-Fi and Bluetooth have been found to be quite inaccurate when it comes to indoor localisation, which is crucial for a visually impaired user that is really relying on accurate information to be provided to him about the space they are in at all times. Lastly, we have found LiDAR on its own to be ridiculously expensive to get when it is a reliable, fast one, or completely inadequate for personal use when the LiDAR is cheap. You can find further information on these findings here .","title":"Computer Vision"}]}